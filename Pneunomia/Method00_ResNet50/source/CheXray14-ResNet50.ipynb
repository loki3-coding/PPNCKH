{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import lib"},{"metadata":{"_cell_guid":"f42f6560-edf0-4efb-85a6-6e945e50895b","_uuid":"3300a1edbf2e8122d88093998eb503a6fab8a719","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Ente\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torch import optim\n\nimport torchvision.transforms as transforms\nimport torchvision\n\nfrom fastprogress import master_bar, progress_bar\n\nfrom PIL import Image\n\nimport math\nimport torch.nn.functional as F\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom glob import glob\n%matplotlib inline\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dataset & Label"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/Data_Entry_2017.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Get labels**"},{"metadata":{"_cell_guid":"9a342cdc-0823-490d-9a3a-a53fb7c33727","_uuid":"fe804e7c294e2d290e27b037bf1ba56177abab70","trusted":true},"cell_type":"code","source":"data['Finding Labels'] = data['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nLABELS = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nLABELS = [x for x in LABELS if len(x)>0]\nprint('All Labels ({}): {}'.format(len(LABELS), LABELS))\nfor c_label in LABELS:\n    if len(c_label)>1: # leave out empty labels\n        data[c_label] = data['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dd273e26-63ab-4d76-925d-9c1c2c1ba69c","_uuid":"9f368f9ea8947d8fc1dacf3988c58b6a2bf5fffc","trusted":true},"cell_type":"code","source":"# keep at least 1000 cases\nMIN_CASES = 1000\nLABELS = [c_label for c_label in LABELS if data[c_label].sum()>MIN_CASES]\nprint('Clean Labels ({})'.format(len(LABELS)), \n      [(c_label,int(data[c_label].sum())) for c_label in LABELS])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData = pd.DataFrame()\nnewData['filename'] = data['Image Index']\n\nfor c_label in LABELS:\n    if len(c_label)>1: # leave out empty labels\n        newData[c_label] = data['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\n\ndata = newData\nprint(data)\n#newData.to_csv('newData_Entry_2017.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Draw histogram**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#label_counts = 100*np.mean(data[LABELS].values,0)\nlabel_counts = [int(data[c_label].sum()) for c_label in LABELS]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts)) + 0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts)) + 0.5)\nax1.set_xticklabels(LABELS, rotation = 90)\n\nax1.set_title('Amount Pictures of Diseases in Patient Group')\n_ = ax1.set_ylabel('Amount')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data is very imbalance. Let do something**"},{"metadata":{"_cell_guid":"a1367d63-4c7b-4e47-b19f-9a26d1f89476","_uuid":"6ed6489bbd618fb419ceca2bbd8c300694f1d4ed","scrolled":true},"cell_type":"markdown","source":"# Prepare Training Data\nsplit data to train folder and valid folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, valid_test_data = train_test_split(data, test_size=0.4, random_state=2019)\nvalid_data, test_data = train_test_split(valid_test_data, test_size=0.5, random_state=2019)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7178cb8d-f220-4422-93ae-2469f0c97493","_uuid":"0115346eb989e7eaeffa3643d05c654ec5ceb7c2"},"cell_type":"markdown","source":"# Create Data Generators\nHere we make the data generators for loading and randomly transforming images"},{"metadata":{"_cell_guid":"30eaf01b-8ec0-4407-9d25-f87ca1f48e8a","_uuid":"b5e42124376584390e925a06c4cee564285e43b3","trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 224                              # Image size (224x224)\nIMAGENET_MEAN = [0.485, 0.456, 0.406]         # Mean of ImageNet dataset (used for normalization)\nIMAGENET_STD = [0.229, 0.224, 0.225]          # Std of ImageNet dataset (used for normalization)\nBATCH_SIZE = 177                          \nLEARNING_RATE = 0.001\nLEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\nLEARNING_RATE_SCHEDULE_PATIENCE = 5           # Parameter used for reducing learning rate\nMAX_EPOCHS = 100                              # Maximum number of training epochs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create Dataloader**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def midPathDataLoader():\n    path_origin = os.path.abspath(os.path.join('..', 'input'))\n    count_img = np.zeros(13, dtype = int)\n    mid_dir = []\n    for i in range(1, 13):\n        path_folder = os.path.join(path_origin, \"images_0\" + ('0' if i < 10 else '') + str(i), \"images\")\n        count_img[i] = (0 if i < 2 else count_img[i-1]) + len(glob(os.path.join(path_folder, \"*.png\")))\n        for j in range((0 if i < 2 else count_img[i-1]) + 1, count_img[i] + 1):\n            mid_dir.append(\"images_0\" + ('0' if i < 10 else '') + str(i) + \"/images\")\n    return mid_dir\n    \nmid_dir = midPathDataLoader()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b67dc5fa-d91b-420a-aaa7-b3991313127a","_uuid":"dbb93f7f8248031563ec7042d978650c0c957c1f","trusted":true},"cell_type":"code","source":"class FundusDataset(Dataset):\n    \n    def __init__(self, folder_dir, dataframe, image_size, normalization):\n        \"\"\"\n        Init Dataset\n        \n        Parameters\n        ----------\n        folder_dir: str\n            folder contains all images\n        dataframe: pandas.DataFrame\n            dataframe contains all information of images\n        image_size: int\n            image size to rescale\n        normalization: bool\n            whether applying normalization with mean and std from ImageNet or not\n        \"\"\"\n        self.image_paths = [] # List of image paths\n        self.image_labels = [] # List of image labels\n        \n        # Define list of image transformations\n        image_transformation = [\n            transforms.Resize((image_size, image_size)),\n            transforms.ToTensor()\n        ]\n        \n        if normalization:\n            # Normalization with mean and std from ImageNet\n            image_transformation.append(transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD))\n        \n        self.image_transformation = transforms.Compose(image_transformation)\n        \n        # Get all image paths and image labels from dataframe\n        for index, row in dataframe.iterrows():\n            image_path = os.path.join(folder_dir, mid_dir[index],row.filename)\n            self.image_paths.append(image_path)\n            self.image_labels.append(row[1:])\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, index):\n        \"\"\"\n        Read image at index and convert to torch Tensor\n        \"\"\"\n        \n        # Read image\n        image_path = self.image_paths[index]\n        image_data = Image.open(image_path).convert(\"RGB\") # Convert image to RGB channels\n        \n        # TODO: Image augmentation code would be placed here\n        \n        # Resize and convert image to torch tensor \n        image_data = self.image_transformation(image_data)\n        \n        return image_data, torch.FloatTensor(self.image_labels[index])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dc4d027c-f5c4-48b8-8ab6-b41971ad514f","_uuid":"cc92b74f28987fee4971e60a71f74660693f4278","trusted":true},"cell_type":"code","source":"train_dataset = FundusDataset(\"../input\", train_data, IMAGE_SIZE, True)\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0621048f-3d4c-4eb7-aaee-0c53f7cbf26a","_uuid":"2852ef2fe07eb6d8e2caf056d1428d153afad65f","trusted":true},"cell_type":"code","source":"val_dataset = FundusDataset(\"../input\", valid_data, IMAGE_SIZE, True)\nval_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data, label in train_dataloader:\n    print(data.size())\n    print(label.size())\n    break","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cce3c89c-4292-4092-9317-ca066d72e354","_uuid":"5b0ec78f2ffa8137dce37744f38a40782aafb54d"},"cell_type":"markdown","source":"# Create a simple model\nUse more model"},{"metadata":{"_cell_guid":"235846d4-3ef1-4888-a276-6134ad572415","_uuid":"a447f8cc7274c06555849a40881fb903aca7001a","trusted":true},"cell_type":"code","source":"class ResNet50(nn.Module):\n    def __init__(self, num_classes, is_trained=True):\n        \n        super().__init__()\n        \n        # Load the resnet50 from ImageNet\n        self.net = torchvision.models.resnet50(pretrained=is_trained)\n        \n        # freeze all the network except the final layer\n        for param in self.net.parameters():\n            param.requires_grad = False\n        \n        # Get the input dimension of last layer\n        kernel_count = self.net.fc.in_features\n        \n        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n        self.net.fc = nn.Sequential(nn.Linear(kernel_count, num_classes), nn.Sigmoid())\n        \n    def forward(self, inputs):\n        \n        return self.net(inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class VGG16(nn.Module):\n    def __init__(self, num_classes, is_trained=True):\n        \n        super().__init__()\n        \n        # Load the resnet50 from ImageNet\n        self.net = torchvision.models.vgg16(pretrained=is_trained)\n\n        # Get the input dimension of last layer\n        kernel_count = self.net.classifier[6].in_features\n        \n        # Replace last layer with new layer that have num_classes node\n        self.net.classifier[6] = nn.Linear(kernel_count, num_classes)\n        \n    def forward(self, inputs):\n        \n        return self.net(inputs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check GPU available**"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1acd1753-dae2-440d-a9d5-f3bbebfe446f","_uuid":"90a131f99bea8b77fba54024e261a97e24dfc6c1","trusted":true},"cell_type":"code","source":"model = ResNet50(num_classes=len(LABELS)).to(device)\nmodel","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e5ad629e-15a3-4c96-ac74-db8077b101fe","_uuid":"eba5247e4a767def4b4ead6e2f02f3c334edbbf0"},"cell_type":"markdown","source":"> # Define loss func, optimizer, and learning rate scheduler\n"},{"metadata":{"_cell_guid":"c269083c-7617-4c16-8f96-353c1f3d8eef","_uuid":"cbdfcf827510dfb3bdba6ab08ff60e21838d6987","trusted":true},"cell_type":"code","source":"# Loss function\nloss_criteria = nn.BCELoss()\n\n# Adam optimizer\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n\n# Learning rate will be reduced automatically during training\nlr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = LEARNING_RATE_SCHEDULE_FACTOR, patience = LEARNING_RATE_SCHEDULE_PATIENCE, mode = 'max', verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"571df602-c0f1-4ba0-9f1e-0c9fdc10eff3","_uuid":"392f3973459dcbb3fc998191baca4d047995d351"},"cell_type":"markdown","source":"# Compute F1 score"},{"metadata":{"_cell_guid":"d9f519ef-4b4f-4bd9-8989-643b21cb8904","_uuid":"308a85cd454ad05e451ec1db99432c6fe85e8e41","trusted":true},"cell_type":"code","source":"def multi_label_f1(y_gt, y_pred):\n    \"\"\" Calculate F1 for each class\n\n    Parameters\n    ----------\n    y_gt: torch.Tensor\n        groundtruth\n    y_pred: torch.Tensor\n        prediction\n\n    Returns\n    -------\n    list\n        F1 of each class\n    \"\"\"\n    f1_out = []\n    gt_np = y_gt.to(\"cpu\").numpy()\n    pred_np = (y_pred.to(\"cpu\").numpy() > 0.5) * 1.0\n    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n    for i in range(gt_np.shape[1]):\n        f1_out.append(f1_score(gt_np[:, i], pred_np[:, i]))\n    return f1_out","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7a0fc649-158c-4844-9b05-f6a62214009f","_uuid":"4acd4919e0ba24e2d06ef75fbb054a907a582c7a"},"cell_type":"markdown","source":"# **** Training each epoch****"},{"metadata":{"_cell_guid":"cc076f02-0bf2-4d3f-a6ab-f192bed9e6a9","_uuid":"d7168d90928d842c295c64e2446e84eb068fd391","trusted":true},"cell_type":"code","source":"def epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb):\n    \"\"\"\n    Epoch training\n\n    Paramteters\n    -----------\n    epoch: int\n      epoch number\n    model: torch Module\n      model to train\n    train_dataloader: Dataset\n      data loader for training\n    device: str\n      \"cpu\" or \"cuda\"\n    loss_criteria: loss function\n      loss function used for training\n    optimizer: torch optimizer\n      optimizer used for training\n    mb: master bar of fastprogress\n      progress to log\n\n    Returns\n    -------\n    float\n      training loss\n    \"\"\"\n    # Switch model to training mode\n    model.train()\n    training_loss = 0 # Storing sum of training losses\n    \n    # For each batch\n    for batch, (images, labels) in enumerate(progress_bar(train_dataloader, parent=mb)):\n        \n        # Move X, Y  to device (GPU)\n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # Clear previous gradient\n        optimizer.zero_grad()\n        \n        # Feed forward the model\n        pred = model(images)\n        loss = loss_criteria(pred, labels)\n\n        # Back propagation\n        loss.backward()\n\n        # Update parameters\n        optimizer.step()\n\n        # Update training loss after each batch\n        training_loss += loss.item()\n\n        mb.child.comment = f'Training loss {training_loss/(batch+1)}'\n\n    del images, labels, loss\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n\n    # return training loss\n    return training_loss/len(train_dataloader)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6c2fe734-8f87-4537-81e0-d0ce68bc2545","_uuid":"8a03574bc1f2b3441538c2408fc158324d6d23df","collapsed":true},"cell_type":"markdown","source":"# Evaluate Model"},{"metadata":{"_cell_guid":"80b6ede7-052b-4fa2-ab97-bed0199db681","_uuid":"0b35cd7ef77680d2aa180812622d89388b8fff63","trusted":true},"cell_type":"code","source":"def evaluating(epoch, model, val_loader, device, loss_criteria, mb):\n    \"\"\"\n    Validate model on validation dataset\n    \n    Parameters\n    ----------\n    epoch: int\n        epoch number\n    model: torch Module\n        model used for validation\n    val_loader: Dataset\n        data loader of validation set\n    device: str\n        \"cuda\" or \"cpu\"\n    loss_criteria: loss function\n      loss function used for training\n    mb: master bar of fastprogress\n      progress to log\n  \n    Returns\n    -------\n    float\n        loss on validation set\n    float\n        metric score on validation set\n    \"\"\"\n\n    # Switch model to evaluation mode\n    model.eval()\n    \n    val_loss = 0                                   # Total loss of model on validation set\n    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n    out_gt = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n\n    with torch.no_grad(): # Turn off gradient\n        # For each batch\n        for step, (images, labels) in enumerate(progress_bar(val_loader, parent=mb)):\n            # Move images, labels to device (GPU)\n            images = images.to(device)\n            labels = labels.to(device)\n\n            # Update groundtruth values\n            out_gt = torch.cat((out_gt,  labels), 0)\n\n            # Feed forward the model\n            ps = model(images)\n            loss = loss_criteria(ps, labels)\n\n            # Update prediction values\n            out_pred = torch.cat((out_pred, ps), 0)\n\n            # Update validation loss after each batch\n            val_loss += loss\n            mb.child.comment = f'Validation loss {val_loss/(step+1)}'\n\n    # Clear memory\n    del images, labels, loss\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n    # return validation loss, and metric score\n    return val_loss/len(val_loader), np.array(multi_label_f1(out_gt, out_pred)).mean()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a50931b1-4d88-4b2f-93f7-ad3c9de31e5c","_uuid":"8ad061d6b08b9ff383f682c35c8b55f30fb560a1"},"cell_type":"markdown","source":" # Fully training"},{"metadata":{"_cell_guid":"714ada59-850d-4d88-b983-2f9107f36e70","_uuid":"e5191706a55a5ab8b68773d0b881aac4b020795a","trusted":true},"cell_type":"code","source":"# Best F1 value during training\nbest_score = 0\nmodel_path = \"Resnet50.pth\"\ntraining_losses = []\nvalidation_losses = []\nvalidation_score = []\n\n\n# Config progress bar\nmb = master_bar(range(MAX_EPOCHS))\nmb.names = ['Training loss', 'Validation loss', 'Validation F1']\nx = []\n\n# Training each epoch\nfor epoch in mb:\n    mb.first_bar.comment = f'Best F1 score: {best_score}'\n    x.append(epoch)\n\n    # Training\n    train_loss = epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb)\n    # mb.write('Finish training epoch {} with loss {:.4f}'.format(epoch, train_loss))\n    training_losses.append(train_loss)\n\n    # Evaluating\n    val_loss, new_score = evaluating(epoch, model, val_dataloader, device, loss_criteria, mb)\n    # mb.write('Finish validation epoch {} with loss {:.4f} and score {:.4f}'.format(epoch, val_loss, new_score))\n    validation_losses.append(val_loss)\n    validation_score.append(new_score)\n\n    # Update learning rate\n    lr_scheduler.step(new_score)\n\n    # Update training chart\n    mb.update_graph([[x, training_losses], [x, validation_score]], [0,MAX_EPOCHS], [0,1])\n\n    # Save model\n    if best_score < new_score:\n        mb.write(f\"Improve F1 from {best_score} to {new_score}\")\n        best_score = new_score\n\n        # Saving model: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n        torch.save(model.state_dict(), model_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ** Now is time to test **"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = FundusDataset(\"../input\", test_data, IMAGE_SIZE, True)\ntest_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def testing(model, test_loader):\n    \"\"\"\n    Validate model on validation dataset\n    \n    Parameters\n    ----------\n    model: torch Module\n        model used for validation\n    test_loader: Dataset\n        data loader of test set\n  \n    Returns\n    -------\n    float\n        metric score on validation set\n    \"\"\"\n\n    # Load model & Switch model to test mode\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    \n    test_error = 0                                 # Total loss of model on validation set\n    total = 0\n    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n    out_gt = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n\n    with torch.no_grad():\n      for step, (images, labels) in enumerate(progress_bar(test_loader, parent=mb)):\n          # Move images, labels to device (GPU)\n          images = images.to(device)\n          labels = labels.to(device)\n            \n          \n          # Get values of each label\n          output = model(images)\n\n          # Compare with thresh hold & calculator test_error\n          test_error+= (output != labels).sum()\n          total+= 1\n          \n\n    # Clear memory\n    del images, labels\n    if torch.cuda.is_available(): torch.cuda.empty_cache()\n    # return test_error\n    return test_error/total","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_error = testing(model, test_dataloader)\nprint(\"Test error = \", test_error)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","version":"3.6.4","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}