{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run on Google Colab, run the code below to download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'train', 'test', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>opacity</th>\n",
       "      <th>diabetic retinopathy</th>\n",
       "      <th>glaucoma</th>\n",
       "      <th>macular edema</th>\n",
       "      <th>macular degeneration</th>\n",
       "      <th>retinal vascular occlusion</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c24a1b14d253.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ee905a41651.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3f58d128caf6.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ce6599e7b20.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0def470360e4.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  opacity   ...    retinal vascular occlusion  normal\n",
       "0  c24a1b14d253.jpg        0   ...                             1       0\n",
       "1  9ee905a41651.jpg        0   ...                             1       0\n",
       "2  3f58d128caf6.jpg        0   ...                             0       0\n",
       "3  4ce6599e7b20.jpg        1   ...                             0       0\n",
       "4  0def470360e4.jpg        1   ...                             0       0\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../input/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analyzing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze distribution of 0 and 1 for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of opacity\n",
      "0    1902\n",
      "1    1533\n",
      "Name: opacity, dtype: int64\n",
      "Distribution of diabetic retinopathy\n",
      "0    2680\n",
      "1     755\n",
      "Name: diabetic retinopathy, dtype: int64\n",
      "Distribution of glaucoma\n",
      "0    2838\n",
      "1     597\n",
      "Name: glaucoma, dtype: int64\n",
      "Distribution of macular edema\n",
      "0    2919\n",
      "1     516\n",
      "Name: macular edema, dtype: int64\n",
      "Distribution of macular degeneration\n",
      "0    2861\n",
      "1     574\n",
      "Name: macular degeneration, dtype: int64\n",
      "Distribution of retinal vascular occlusion\n",
      "0    2995\n",
      "1     440\n",
      "Name: retinal vascular occlusion, dtype: int64\n",
      "Distribution of normal\n",
      "0    2910\n",
      "1     525\n",
      "Name: normal, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for label in data.columns[1:]:\n",
    "    print(\"Distribution of\", label)\n",
    "    print(data[label].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be observed, the number of label 0 is much more larger than label 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze combination of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opacity                                                                  671\n",
       "normal                                                                   525\n",
       "glaucoma                                                                 327\n",
       "macular degeneration                                                     299\n",
       "opacity,macular degeneration                                             212\n",
       "diabetic retinopathy                                                     212\n",
       "opacity,diabetic retinopathy                                             186\n",
       "retinal vascular occlusion                                               170\n",
       "diabetic retinopathy,macular edema                                       162\n",
       "opacity,diabetic retinopathy,macular edema                               154\n",
       "opacity,glaucoma                                                         140\n",
       "macular edema,retinal vascular occlusion                                  74\n",
       "opacity,macular edema,retinal vascular occlusion                          62\n",
       "opacity,retinal vascular occlusion                                        55\n",
       "glaucoma,macular degeneration                                             31\n",
       "glaucoma,retinal vascular occlusion                                       27\n",
       "macular edema                                                             27\n",
       "opacity,glaucoma,macular degeneration                                     16\n",
       "diabetic retinopathy,glaucoma                                             15\n",
       "glaucoma,macular edema,retinal vascular occlusion                         14\n",
       "opacity,glaucoma,retinal vascular occlusion                               10\n",
       "opacity,glaucoma,macular edema,retinal vascular occlusion                  8\n",
       "diabetic retinopathy,retinal vascular occlusion                            5\n",
       "opacity,diabetic retinopathy,macular degeneration                          5\n",
       "opacity,diabetic retinopathy,retinal vascular occlusion                    4\n",
       "opacity,macular degeneration,retinal vascular occlusion                    3\n",
       "glaucoma,macular edema                                                     3\n",
       "diabetic retinopathy,glaucoma,macular edema                                3\n",
       "macular degeneration,retinal vascular occlusion                            2\n",
       "opacity,diabetic retinopathy,macular edema,retinal vascular occlusion      2\n",
       "glaucoma,macular degeneration,retinal vascular occlusion                   2\n",
       "opacity,diabetic retinopathy,macular edema,macular degeneration            2\n",
       "diabetic retinopathy,macular edema,retinal vascular occlusion              2\n",
       "diabetic retinopathy,macular degeneration                                  2\n",
       "opacity,macular edema                                                      2\n",
       "opacity,diabetic retinopathy,glaucoma,macular edema                        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = data.columns[1:]\n",
    "def build_label(row):\n",
    "    return \",\".join([LABELS[idx] for idx, val in enumerate(row[1:]) if val == 1])\n",
    "        \n",
    "data.apply(lambda x: build_label(x), axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['opacity', 'diabetic retinopathy', 'glaucoma', 'macular edema',\n",
       "       'macular degeneration', 'retinal vascular occlusion', 'normal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, **opacity**, **normal** and **glaucoma** are diseases that share largest proportions in label distribution. The other diseases or combinations just account for small pieces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations on the dataset\n",
    "The dataset provided is extremely imbalanced. In this baseline model, by simply train the model the original dataset, we will easily get overfitting on the training set and the score on the test set is very low. With the proposed methods below, you will tweak the training process and improve the metric score on the test set:\n",
    "- **Image Augmentation**: By augmenting images, we will have more data and make the training set become more regularize. [imgaug](https://github.com/aleju/imgaug) is a very strong augmentation library that you can use in this assignment\n",
    "- **Data sampling**: the idea here is to make the distribution between classes in the dataset balance. There are 2 kinds: oversampling and undersampling\n",
    "- **Adjust loss function**: the current loss function becomes very small after several epochs. By adding weights, we adjust the loss function to make it suitable for this imbalanced dataset. You can check the [BCEWithLogitsLoss](https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss) and try applying it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data provided, we will split the dataset to 80% for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To simplify the baseline model, the dataset is splited randomly. However, to improve the model, cross-validation techniques can be applied here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and train baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use Pytorch library to implement and train ResNet50 as a baseline model. With initial weights from ImageNet, we will retrain all layers for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224                              # Image size (224x224)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]         # Mean of ImageNet dataset (used for normalization)\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]          # Std of ImageNet dataset (used for normalization)\n",
    "BATCH_SIZE = 20                           \n",
    "LEARNING_RATE = 0.001\n",
    "LEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\n",
    "LEARNING_RATE_SCHEDULE_PATIENCE = 5           # Parameter used for reducing learning rate\n",
    "MAX_EPOCHS = 100                              # Maximum number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Dataset loader\n",
    "In Pytorch, you need to subclass the `Dataset` of Pytorch to custom the data loading process. The **Image Augmentation** would be executed in this subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FundusDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, folder_dir, dataframe, image_size, normalization):\n",
    "        \"\"\"\n",
    "        Init Dataset\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        folder_dir: str\n",
    "            folder contains all images\n",
    "        dataframe: pandas.DataFrame\n",
    "            dataframe contains all information of images\n",
    "        image_size: int\n",
    "            image size to rescale\n",
    "        normalization: bool\n",
    "            whether applying normalization with mean and std from ImageNet or not\n",
    "        \"\"\"\n",
    "        self.image_paths = [] # List of image paths\n",
    "        self.image_labels = [] # List of image labels\n",
    "        \n",
    "        # Define list of image transformations\n",
    "        image_transformation = [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "        \n",
    "        if normalization:\n",
    "            # Normalization with mean and std from ImageNet\n",
    "            image_transformation.append(transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD))\n",
    "        \n",
    "        self.image_transformation = transforms.Compose(image_transformation)\n",
    "        \n",
    "        # Get all image paths and image labels from dataframe\n",
    "        for index, row in dataframe.iterrows():\n",
    "            image_path = os.path.join(folder_dir, row.filename)\n",
    "            self.image_paths.append(image_path)\n",
    "            self.image_labels.append(row[1:])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Read image at index and convert to torch Tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        # Read image\n",
    "        image_path = self.image_paths[index]\n",
    "        image_data = Image.open(image_path).convert(\"RGB\") # Convert image to RGB channels\n",
    "        \n",
    "        # TODO: Image augmentation code would be placed here\n",
    "        \n",
    "        # Resize and convert image to torch tensor \n",
    "        image_data = self.image_transformation(image_data)\n",
    "        \n",
    "        return image_data, torch.FloatTensor(self.image_labels[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FundusDataset(\"../input/train/train\", train_data, IMAGE_SIZE, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, `DataLoader` also need to be created. For the training data loader, we need to shuffle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the size of data and label for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 224, 224])\n",
      "torch.Size([20, 7])\n"
     ]
    }
   ],
   "source": [
    "for data, label in train_dataloader:\n",
    "    print(data.size())\n",
    "    print(label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to create validation dataloader. Different from training dataloader, we don't shuffle the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = FundusDataset(\"../input/train/train\", val_data, IMAGE_SIZE, True)\n",
    "val_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "In the baseline, we use ResNet50 pretrained on ImageNet dataset. The classifier of model would be replaced with a new dense layer to make the output suit the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes, is_trained=True):\n",
    "        \"\"\"\n",
    "        Init model architecture\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes: int\n",
    "            number of classes\n",
    "        is_trained: bool\n",
    "            whether using pretrained model from ImageNet or not\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load the resnet50 from ImageNet\n",
    "        self.net = torchvision.models.resnet50(pretrained=is_trained)\n",
    "        \n",
    "        # freeze \n",
    "        for param in model.parameters():\n",
    "            param.require_grad = False\n",
    "        \n",
    "        # Get the input dimension of last layer\n",
    "        kernel_count = self.net.fc.in_features\n",
    "        \n",
    "        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n",
    "        self.net.fc = nn.Sequential(nn.Linear(kernel_count, num_classes), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward the netword with the inputs\n",
    "        \"\"\"\n",
    "        return self.net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_classes, is_trained=True):\n",
    "        \"\"\"\n",
    "        Init model architecture\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes: int\n",
    "            number of classes\n",
    "        is_trained: bool\n",
    "            whether using pretrained model from ImageNet or not\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load the resnet50 from ImageNet\n",
    "        self.net = torchvision.models.densenet121(pretrained=is_trained)\n",
    "        \n",
    "        # freeze \n",
    "        for param in self.net.parameters():\n",
    "            param.require_grad = False\n",
    "        \n",
    "        # Get the input dimension of last layer\n",
    "        kernel_count = self.net.classifier.in_features\n",
    "        \n",
    "        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n",
    "        self.net.classifier = nn.Sequential(nn.Linear(kernel_count, num_classes), nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward the netword with the inputs\n",
    "        \"\"\"\n",
    "        return self.net(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and get number of trainable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model and check model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /tmp/.cache/torch/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 32342954/32342954 [00:00<00:00, 80114583.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseNet121(\n",
       "  (net): DenseNet(\n",
       "    (features): Sequential(\n",
       "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu0): ReLU(inplace)\n",
       "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (denseblock1): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition1): _Transition(\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock2): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition2): _Transition(\n",
       "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock3): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition3): _Transition(\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock4): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=7, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DenseNet121(num_classes=len(LABELS)).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6961031"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to train about 23 millions parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function, optimizer, and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_criteria = nn.BCELoss()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate will be reduced automatically during training\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = LEARNING_RATE_SCHEDULE_FACTOR, patience = LEARNING_RATE_SCHEDULE_PATIENCE, mode = 'max', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute F1-score \n",
    "Because we have multi labels, we need to calculate F1-score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_f1(y_gt, y_pred):\n",
    "    \"\"\" Calculate F1 for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        F1 of each class\n",
    "    \"\"\"\n",
    "    f1_out = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = (y_pred.to(\"cpu\").numpy() > 0.5) * 1.0\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        f1_out.append(f1_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return f1_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training each epoch\n",
    "This function will be called to train on one epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb):\n",
    "    \"\"\"\n",
    "    Epoch training\n",
    "\n",
    "    Paramteters\n",
    "    -----------\n",
    "    epoch: int\n",
    "      epoch number\n",
    "    model: torch Module\n",
    "      model to train\n",
    "    train_dataloader: Dataset\n",
    "      data loader for training\n",
    "    device: str\n",
    "      \"cpu\" or \"cuda\"\n",
    "    loss_criteria: loss function\n",
    "      loss function used for training\n",
    "    optimizer: torch optimizer\n",
    "      optimizer used for training\n",
    "    mb: master bar of fastprogress\n",
    "      progress to log\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "      training loss\n",
    "    \"\"\"\n",
    "    # Switch model to training mode\n",
    "    model.train()\n",
    "    training_loss = 0 # Storing sum of training losses\n",
    "   \n",
    "    # For each batch\n",
    "    for batch, (images, labels) in enumerate(progress_bar(train_dataloader, parent=mb)):\n",
    "        \n",
    "        # Move X, Y  to device (GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear previous gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Feed forward the model\n",
    "        pred = model(images)\n",
    "        loss = loss_criteria(pred, labels)\n",
    "\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training loss after each batch\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        mb.child.comment = f'Training loss {training_loss/(batch+1)}'\n",
    "\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    # return training loss\n",
    "    return training_loss/len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model\n",
    "This function is used to validate the model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(epoch, model, val_loader, device, loss_criteria, mb):\n",
    "    \"\"\"\n",
    "    Validate model on validation dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch: int\n",
    "        epoch number\n",
    "    model: torch Module\n",
    "        model used for validation\n",
    "    val_loader: Dataset\n",
    "        data loader of validation set\n",
    "    device: str\n",
    "        \"cuda\" or \"cpu\"\n",
    "    loss_criteria: loss function\n",
    "      loss function used for training\n",
    "    mb: master bar of fastprogress\n",
    "      progress to log\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        loss on validation set\n",
    "    float\n",
    "        metric score on validation set\n",
    "    \"\"\"\n",
    "\n",
    "    # Switch model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0                                   # Total loss of model on validation set\n",
    "    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n",
    "    out_gt = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n",
    "\n",
    "    with torch.no_grad(): # Turn off gradient\n",
    "        # For each batch\n",
    "        for step, (images, labels) in enumerate(progress_bar(val_loader, parent=mb)):\n",
    "            # Move images, labels to device (GPU)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Update groundtruth values\n",
    "            out_gt = torch.cat((out_gt,  labels), 0)\n",
    "\n",
    "            # Feed forward the model\n",
    "            ps = model(images)\n",
    "            loss = loss_criteria(ps, labels)\n",
    "\n",
    "            # Update prediction values\n",
    "            out_pred = torch.cat((out_pred, ps), 0)\n",
    "\n",
    "            # Update validation loss after each batch\n",
    "            val_loss += loss\n",
    "            mb.child.comment = f'Validation loss {val_loss/(step+1)}'\n",
    "\n",
    "    # Clear memory\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    # return validation loss, and metric score\n",
    "    return val_loss/len(val_loader), np.array(multi_label_f1(out_gt, out_pred)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully training\n",
    "Fully training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10' class='' max='100', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.00% [10/100 07:02<1:03:25 Best F1 score: 0.8502146560327278]\n",
       "    </div>\n",
       "    \n",
       "Finish training epoch 0 with loss 0.3828<p>Finish validation epoch 0 with loss 0.3937 and score 0.5032<p>Improve F1 from 0 to 0.5032202251248895<p>Finish training epoch 1 with loss 0.3205<p>Finish validation epoch 1 with loss 0.3166 and score 0.5395<p>Improve F1 from 0.5032202251248895 to 0.5394945762808462<p>Finish training epoch 2 with loss 0.2881<p>Finish validation epoch 2 with loss 0.3033 and score 0.6334<p>Improve F1 from 0.5394945762808462 to 0.6334111731510411<p>Finish training epoch 3 with loss 0.2693<p>Finish validation epoch 3 with loss 0.2305 and score 0.7019<p>Improve F1 from 0.6334111731510411 to 0.701878635423627<p>Finish training epoch 4 with loss 0.2443<p>Finish validation epoch 4 with loss 0.2620 and score 0.6308<p>Finish training epoch 5 with loss 0.2250<p>Finish validation epoch 5 with loss 0.2085 and score 0.7337<p>Improve F1 from 0.701878635423627 to 0.7336828720952954<p>Finish training epoch 6 with loss 0.2124<p>Finish validation epoch 6 with loss 0.2309 and score 0.7055<p>Finish training epoch 7 with loss 0.2013<p>Finish validation epoch 7 with loss 0.1815 and score 0.8124<p>Improve F1 from 0.7336828720952954 to 0.8124148642183792<p>Finish training epoch 8 with loss 0.1871<p>Finish validation epoch 8 with loss 0.1488 and score 0.8502<p>Improve F1 from 0.8124148642183792 to 0.8502146560327278<p>Finish training epoch 9 with loss 0.1731<p>Finish validation epoch 9 with loss 0.1759 and score 0.8179<p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='98' class='' max='138', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      71.01% [98/138 00:18<00:07 Training loss 0.1610855711814092]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Best F1 value during training\n",
    "best_score = 0\n",
    "model_path = \"resnet50.pth\"\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "validation_score = []\n",
    "\n",
    "\n",
    "# Config progress bar\n",
    "mb = master_bar(range(MAX_EPOCHS))\n",
    "mb.names = ['Training loss', 'Validation loss', 'Validation F1']\n",
    "x = []\n",
    "\n",
    "# Training each epoch\n",
    "for epoch in mb:\n",
    "    mb.first_bar.comment = f'Best F1 score: {best_score}'\n",
    "    x.append(epoch)\n",
    "\n",
    "    # Training\n",
    "    train_loss = epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb)\n",
    "    mb.write('Finish training epoch {} with loss {:.4f}'.format(epoch, train_loss))\n",
    "    training_losses.append(train_loss)\n",
    "\n",
    "    # Evaluating\n",
    "    val_loss, new_score = evaluating(epoch, model, val_dataloader, device, loss_criteria, mb)\n",
    "    mb.write('Finish validation epoch {} with loss {:.4f} and score {:.4f}'.format(epoch, val_loss, new_score))\n",
    "    validation_losses.append(val_loss)\n",
    "    validation_score.append(new_score)\n",
    "\n",
    "    # Update learning rate\n",
    "    lr_scheduler.step(new_score)\n",
    "\n",
    "    # Update training chart\n",
    "    mb.update_graph([[x, training_losses], [x, validation_losses], [x, validation_score]], [0,MAX_EPOCHS], [0,1])\n",
    "\n",
    "    # Save model\n",
    "    if best_score < new_score:\n",
    "        mb.write(f\"Improve F1 from {best_score} to {new_score}\")\n",
    "        best_score = new_score\n",
    "\n",
    "        # Saving model: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "        torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e742d34a26d4.jpg</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b193b6a6d68d.jpg</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07e4191fa3a8.jpg</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b1a911cb2e6c.jpg</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d8ab9cda1b33.jpg</td>\n",
       "      <td>0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename predicted\n",
       "0  e742d34a26d4.jpg       0 0\n",
       "1  b193b6a6d68d.jpg       0 0\n",
       "2  07e4191fa3a8.jpg       0 0\n",
       "3  b1a911cb2e6c.jpg       0 0\n",
       "4  d8ab9cda1b33.jpg       0 0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of image transformations\n",
    "image_transformation = [\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "]\n",
    "# Normalization with mean and std from ImageNet\n",
    "image_transformation.append(transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD))\n",
    "image_transformation = transforms.Compose(image_transformation)\n",
    "\n",
    "def predict(image_path, model, device):\n",
    "    \"\"\" Predict image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path: str\n",
    "        image path to predict\n",
    "    model: nn.Module\n",
    "        model used to predict\n",
    "    device: str\n",
    "        'cpu' or 'cuda'\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        list of label indices\n",
    "    \"\"\"\n",
    "    global image_transformation\n",
    "    \n",
    "    # Read image\n",
    "    image_data = Image.open(image_path).convert('RGB')\n",
    "    image_data = image_transformation(image_data)\n",
    "    \n",
    "    predicted_label = []\n",
    "    with torch.no_grad():\n",
    "        ps = model(image_data.unsqueeze(0).to(device))\n",
    "        ps = ps[0]\n",
    "        for i in range(ps.size()[0]):\n",
    "            if ps[i].item() > 0.5: # Threshold is 0.5\n",
    "                predicted_label.append(i)\n",
    "    return \" \".join([str(label) for label in predicted_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best model weights and switch to evaludation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet121(\n",
       "  (net): DenseNet(\n",
       "    (features): Sequential(\n",
       "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu0): ReLU(inplace)\n",
       "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (denseblock1): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition1): _Transition(\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock2): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition2): _Transition(\n",
       "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock3): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition3): _Transition(\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock4): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=7, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted'] = test_df.filename.map(lambda x: predict(os.path.join(\"../input/test/test\",x), model, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write result to submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train with DenseNet 121, Adam, BCELoss. Error = ? Start: 0h25'\n",
    "- Train with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  __output__.json  resnet50.pth  submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
