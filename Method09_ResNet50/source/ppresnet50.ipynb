{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224                              # Image size (224x224)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]         # Mean of ImageNet dataset (used for normalization)\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]          # Std of ImageNet dataset (used for normalization)\n",
    "BATCH_SIZE = 120                         \n",
    "LEARNING_RATE = 0.001\n",
    "LEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\n",
    "LEARNING_RATE_SCHEDULE_PATIENCE = 5           # Parameter used for reducing learning rate\n",
    "MAX_EPOCHS = 70\n",
    "\n",
    "USE_BCELOGIT = True\n",
    "USE_WEIGHT = True\n",
    "# LOSS WEIGHT\n",
    "pos_w = None\n",
    "w = None\n",
    "if USE_WEIGHT:\n",
    "    pos_w=[1.04]\n",
    "    w = [1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Define path to the data directory\n",
    "data_dir = Path('../input/chest_xray/chest_xray')\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = data_dir / 'train'\n",
    "\n",
    "# Path to validation directory\n",
    "val_dir = data_dir / 'val'\n",
    "\n",
    "# Path to test directory\n",
    "test_dir = data_dir / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load img**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/chest_xray/chest_xray/train/NORMAL/NO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/chest_xray/chest_xray/train/PNEUMONIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/chest_xray/chest_xray/train/PNEUMONIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/chest_xray/chest_xray/train/NORMAL/NO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/chest_xray/chest_xray/train/PNEUMONIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label\n",
       "0  ../input/chest_xray/chest_xray/train/NORMAL/NO...      0\n",
       "1  ../input/chest_xray/chest_xray/train/PNEUMONIA...      1\n",
       "2  ../input/chest_xray/chest_xray/train/PNEUMONIA...      1\n",
       "3  ../input/chest_xray/chest_xray/train/NORMAL/NO...      0\n",
       "4  ../input/chest_xray/chest_xray/train/PNEUMONIA...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = train_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "train_data = []\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in normal_cases:\n",
    "    train_data.append((img,0))\n",
    "    # this is overstampling\n",
    "    train_data.append((img,0))\n",
    "    train_data.append((img,0))\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in pneumonia_cases:\n",
    "    train_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list \n",
    "train_data = pd.DataFrame(train_data, columns=['path', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data \n",
    "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/chest_xray/chest_xray/val/PNEUMONIA/p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/chest_xray/chest_xray/val/NORMAL/NORM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/chest_xray/chest_xray/val/NORMAL/NORM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/chest_xray/chest_xray/val/PNEUMONIA/p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/chest_xray/chest_xray/val/PNEUMONIA/p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label\n",
       "0  ../input/chest_xray/chest_xray/val/PNEUMONIA/p...      1\n",
       "1  ../input/chest_xray/chest_xray/val/NORMAL/NORM...      0\n",
       "2  ../input/chest_xray/chest_xray/val/NORMAL/NORM...      0\n",
       "3  ../input/chest_xray/chest_xray/val/PNEUMONIA/p...      1\n",
       "4  ../input/chest_xray/chest_xray/val/PNEUMONIA/p...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = val_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "valid_data = []\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in normal_cases:\n",
    "    valid_data.append((img, 0))\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in pneumonia_cases:\n",
    "    valid_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list \n",
    "valid_data = pd.DataFrame(valid_data, columns=['path', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data \n",
    "valid_data = valid_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/chest_xray/chest_xray/test/PNEUMONIA/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/chest_xray/chest_xray/test/NORMAL/NOR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/chest_xray/chest_xray/test/PNEUMONIA/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/chest_xray/chest_xray/test/NORMAL/NOR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/chest_xray/chest_xray/test/NORMAL/NOR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label\n",
       "0  ../input/chest_xray/chest_xray/test/PNEUMONIA/...      1\n",
       "1  ../input/chest_xray/chest_xray/test/NORMAL/NOR...      0\n",
       "2  ../input/chest_xray/chest_xray/test/PNEUMONIA/...      1\n",
       "3  ../input/chest_xray/chest_xray/test/NORMAL/NOR...      0\n",
       "4  ../input/chest_xray/chest_xray/test/NORMAL/NOR...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "test_data = []\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in normal_cases:\n",
    "    test_data.append((img, 0))\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in pneumonia_cases:\n",
    "    test_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list \n",
    "test_data = pd.DataFrame(test_data, columns=['path', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data \n",
    "test_data = test_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Show Figue of Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4023\n",
      "1    3875\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = train_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results \n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "plt.title('Number of cases', fontsize=14)\n",
    "plt.xlabel('Case type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is very imbalance, so we need Aug, Overstampling or Understampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    8\n",
      "0    8\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = valid_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results \n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "plt.title('Number of cases', fontsize=14)\n",
    "plt.xlabel('Case type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    390\n",
      "0    234\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = test_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results \n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "plt.title('Number of cases', fontsize=14)\n",
    "plt.xlabel('Case type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create FudusDataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FundusDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, image_size, normalization):\n",
    "        \"\"\"\n",
    "        Init Dataset\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataframe: pandas.DataFrame\n",
    "            dataframe contains all information of images\n",
    "        image_size: int\n",
    "            image size to rescale\n",
    "        normalization: bool\n",
    "            whether applying normalization with mean and std from ImageNet or not\n",
    "        \"\"\"\n",
    "        self.image_paths = [] # List of image paths\n",
    "        self.image_labels = [] # List of image labels\n",
    "        \n",
    "        # Define list of image transformations\n",
    "        image_transformation = [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "        \n",
    "        if normalization:\n",
    "            # Normalization with mean and std from ImageNet\n",
    "            image_transformation.append(transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD))\n",
    "        \n",
    "        self.image_transformation = transforms.Compose(image_transformation)\n",
    "        \n",
    "        # Get all image paths and image labels from dataframe\n",
    "        for index, row in dataframe.iterrows():\n",
    "            self.image_paths.append(row.path)\n",
    "            self.image_labels.append(row.label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Read image at index and convert to torch Tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        # Read image\n",
    "        image_path = self.image_paths[index]\n",
    "        image_data = Image.open(image_path).convert(\"RGB\") # Convert image to RGB channels\n",
    "        \n",
    "        # TODO: Image augmentation code would be placed here\n",
    "        \n",
    "        # Resize and convert image to torch tensor \n",
    "        image_data = self.image_transformation(image_data)\n",
    "        \n",
    "        return image_data, torch.tensor([self.image_labels[index]*1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FundusDataset(train_data, IMAGE_SIZE, True)\n",
    "valid_dataset = FundusDataset(valid_data, IMAGE_SIZE, True)\n",
    "test_dataset = FundusDataset(test_data, IMAGE_SIZE, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for img, label in test_dataset:\n",
    "    print(img.size())\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "for data, label in valid_dataloader:\n",
    "    print(data.size())\n",
    "    print(label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes, is_trained=True):\n",
    "        \"\"\"\n",
    "        Init model architecture\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes: int\n",
    "            number of classes\n",
    "        is_trained: bool\n",
    "            whether using pretrained model from ImageNet or not\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load the resnet50 from ImageNet\n",
    "        self.net = torchvision.models.resnet50(pretrained=is_trained)\n",
    "        \n",
    "        # freeze False, unfreeze True\n",
    "        for param in self.net.parameters():\n",
    "            param.require_grad = False\n",
    "        \n",
    "        # Get the input dimension of last layer\n",
    "        kernel_count = self.net.fc.in_features\n",
    "        \n",
    "        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n",
    "        self.net.fc = nn.Sequential(nn.Linear(kernel_count, num_classes))\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward the netword with the inputs\n",
    "        \"\"\"\n",
    "        return self.net(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** Create Model & count params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
      "100%|| 102502400/102502400 [00:00<00:00, 160500424.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet50(\n",
       "  (net): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50(num_classes=1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23510081"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function, optimizer, and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "if pos_w is not None:\n",
    "    pos_w = torch.tensor(pos_w, device=device)\n",
    "if w is not None:\n",
    "    w = torch.tensor(w, device=device)\n",
    "\n",
    "if USE_BCELOGIT:\n",
    "    loss_criteria = nn.BCEWithLogitsLoss(weight=w, pos_weight=pos_w)\n",
    "else:\n",
    "    loss_criteria = nn.BCELoss(weight=w)\n",
    "if device == 'cuda':\n",
    "    loss_criteria.cuda()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate will be reduced automatically during training\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = LEARNING_RATE_SCHEDULE_FACTOR, patience = LEARNING_RATE_SCHEDULE_PATIENCE, mode = 'max', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_f1(y_gt, y_pred):\n",
    "    \"\"\" Calculate F1 for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        F1 of each class\n",
    "    \"\"\"\n",
    "    f1_out = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = (y_pred.to(\"cpu\").numpy() > 0.5) * 1.0\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        f1_out.append(f1_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return f1_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training each epoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb):\n",
    "    \"\"\"\n",
    "    Epoch training\n",
    "\n",
    "    Paramteters\n",
    "    -----------\n",
    "    epoch: int\n",
    "      epoch number\n",
    "    model: torch Module\n",
    "      model to train\n",
    "    train_dataloader: Dataset\n",
    "      data loader for training\n",
    "    device: str\n",
    "      \"cpu\" or \"cuda\"\n",
    "    loss_criteria: loss function\n",
    "      loss function used for training\n",
    "    optimizer: torch optimizer\n",
    "      optimizer used for training\n",
    "    mb: master bar of fastprogress\n",
    "      progress to log\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "      training loss\n",
    "    \"\"\"\n",
    "    # Switch model to training mode\n",
    "    model.train()\n",
    "    training_loss = 0 # Storing sum of training losses\n",
    "   \n",
    "    # For each batch\n",
    "    for batch, (images, labels) in enumerate(progress_bar(train_dataloader, parent=mb)):\n",
    "        \n",
    "        # Move X, Y  to device (GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear previous gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Feed forward the model\n",
    "        pred = model(images)\n",
    "        loss = loss_criteria(pred, labels)\n",
    "\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training loss after each batch\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        mb.child.comment = f'Training loss {training_loss/(batch+1)}'\n",
    "\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    # return training loss\n",
    "    return training_loss/len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(epoch, model, val_loader, device, loss_criteria, mb):\n",
    "    \"\"\"\n",
    "    Validate model on validation dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch: int\n",
    "        epoch number\n",
    "    model: torch Module\n",
    "        model used for validation\n",
    "    val_loader: Dataset\n",
    "        data loader of validation set\n",
    "    device: str\n",
    "        \"cuda\" or \"cpu\"\n",
    "    loss_criteria: loss function\n",
    "      loss function used for training\n",
    "    mb: master bar of fastprogress\n",
    "      progress to log\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        loss on validation set\n",
    "    float\n",
    "        metric score on validation set\n",
    "    \"\"\"\n",
    "\n",
    "    # Switch model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0                                   # Total loss of model on validation set\n",
    "    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n",
    "    out_gt = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n",
    "\n",
    "    with torch.no_grad(): # Turn off gradient\n",
    "        # For each batch\n",
    "        for step, (images, labels) in enumerate(progress_bar(val_loader, parent=mb)):\n",
    "            # Move images, labels to device (GPU)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Update groundtruth values\n",
    "            out_gt = torch.cat((out_gt,  labels), 0)\n",
    "\n",
    "            # Feed forward the model\n",
    "            ps = model(images)\n",
    "            loss = loss_criteria(ps, labels)\n",
    "\n",
    "            # Update prediction values\n",
    "            out_pred = torch.cat((out_pred, ps), 0)\n",
    "\n",
    "            # Update validation loss after each batch\n",
    "            val_loss += loss\n",
    "            mb.child.comment = f'Validation loss {val_loss/(step+1)}'\n",
    "\n",
    "    # Clear memory\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    # return validation loss, and metric score\n",
    "    return val_loss/len(val_loader), np.array(multi_label_f1(out_gt, out_pred)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='33' class='' max='70', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      47.14% [33/70 1:20:38<1:30:25 Best F1 score: 1.0]\n",
       "    </div>\n",
       "    \n",
       "Finish training epoch 0 with loss 0.1162<p>Finish validation epoch 0 with loss 0.1354 and score 0.9412<p>Improve F1 from 0 to 0.9411764705882353<p>Finish training epoch 1 with loss 0.0286<p>Finish validation epoch 1 with loss 0.0675 and score 1.0000<p>Improve F1 from 0.9411764705882353 to 1.0<p>Finish training epoch 2 with loss 0.0230<p>Finish validation epoch 2 with loss 0.0129 and score 1.0000<p>Finish training epoch 3 with loss 0.0127<p>Finish validation epoch 3 with loss 0.2937 and score 0.8889<p>Finish training epoch 4 with loss 0.0287<p>Finish validation epoch 4 with loss 0.0146 and score 1.0000<p>Finish training epoch 5 with loss 0.0085<p>Finish validation epoch 5 with loss 0.1297 and score 0.9412<p>Finish training epoch 6 with loss 0.0085<p>Finish validation epoch 6 with loss 0.0100 and score 1.0000<p>Finish training epoch 7 with loss 0.0036<p>Finish validation epoch 7 with loss 0.0256 and score 1.0000<p>Finish training epoch 8 with loss 0.0009<p>Finish validation epoch 8 with loss 0.0171 and score 1.0000<p>Finish training epoch 9 with loss 0.0004<p>Finish validation epoch 9 with loss 0.0160 and score 1.0000<p>Finish training epoch 10 with loss 0.0003<p>Finish validation epoch 10 with loss 0.0154 and score 1.0000<p>Finish training epoch 11 with loss 0.0003<p>Finish validation epoch 11 with loss 0.0295 and score 1.0000<p>Finish training epoch 12 with loss 0.0003<p>Finish validation epoch 12 with loss 0.0108 and score 1.0000<p>Finish training epoch 13 with loss 0.0002<p>Finish validation epoch 13 with loss 0.0106 and score 1.0000<p>Finish training epoch 14 with loss 0.0002<p>Finish validation epoch 14 with loss 0.0117 and score 1.0000<p>Finish training epoch 15 with loss 0.0001<p>Finish validation epoch 15 with loss 0.0125 and score 1.0000<p>Finish training epoch 16 with loss 0.0002<p>Finish validation epoch 16 with loss 0.0110 and score 1.0000<p>Finish training epoch 17 with loss 0.0002<p>Finish validation epoch 17 with loss 0.0102 and score 1.0000<p>Finish training epoch 18 with loss 0.0001<p>Finish validation epoch 18 with loss 0.0116 and score 1.0000<p>Finish training epoch 19 with loss 0.0001<p>Finish validation epoch 19 with loss 0.0083 and score 1.0000<p>Finish training epoch 20 with loss 0.0001<p>Finish validation epoch 20 with loss 0.0143 and score 1.0000<p>Finish training epoch 21 with loss 0.0002<p>Finish validation epoch 21 with loss 0.0133 and score 1.0000<p>Finish training epoch 22 with loss 0.0001<p>Finish validation epoch 22 with loss 0.0139 and score 1.0000<p>Finish training epoch 23 with loss 0.0002<p>Finish validation epoch 23 with loss 0.0095 and score 1.0000<p>Finish training epoch 24 with loss 0.0002<p>Finish validation epoch 24 with loss 0.0064 and score 1.0000<p>Finish training epoch 25 with loss 0.0002<p>Finish validation epoch 25 with loss 0.0115 and score 1.0000<p>Finish training epoch 26 with loss 0.0002<p>Finish validation epoch 26 with loss 0.0120 and score 1.0000<p>Finish training epoch 27 with loss 0.0001<p>Finish validation epoch 27 with loss 0.0092 and score 1.0000<p>Finish training epoch 28 with loss 0.0002<p>Finish validation epoch 28 with loss 0.0126 and score 1.0000<p>Finish training epoch 29 with loss 0.0002<p>Finish validation epoch 29 with loss 0.0060 and score 1.0000<p>Finish training epoch 30 with loss 0.0001<p>Finish validation epoch 30 with loss 0.0126 and score 1.0000<p>Finish training epoch 31 with loss 0.0001<p>Finish validation epoch 31 with loss 0.0130 and score 1.0000<p>Finish training epoch 32 with loss 0.0002<p>Finish validation epoch 32 with loss 0.0149 and score 1.0000<p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='18' class='' max='66', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      27.27% [18/66 00:40<01:48 Training loss 6.276692228210677e-05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     7: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-08.\n"
     ]
    }
   ],
   "source": [
    "# Best F1 value during training\n",
    "best_score = 0\n",
    "model_path = \"resnet50.pth\"\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "validation_score = []\n",
    "\n",
    "\n",
    "# Config progress bar\n",
    "mb = master_bar(range(MAX_EPOCHS))\n",
    "mb.names = ['Training loss', 'Validation loss', 'Validation F1']\n",
    "x = []\n",
    "\n",
    "# Training each epoch\n",
    "for epoch in mb:\n",
    "    mb.first_bar.comment = f'Best F1 score: {best_score}'\n",
    "    x.append(epoch)\n",
    "\n",
    "    # Training\n",
    "    train_loss = epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb)\n",
    "    mb.write('Finish training epoch {} with loss {:.4f}'.format(epoch, train_loss))\n",
    "    training_losses.append(train_loss)\n",
    "\n",
    "    # Evaluating\n",
    "    val_loss, new_score = evaluating(epoch, model, valid_dataloader, device, loss_criteria, mb)\n",
    "    mb.write('Finish validation epoch {} with loss {:.4f} and score {:.4f}'.format(epoch, val_loss, new_score))\n",
    "    validation_losses.append(val_loss)\n",
    "    validation_score.append(new_score)\n",
    "\n",
    "    # Update learning rate\n",
    "    lr_scheduler.step(new_score)\n",
    "\n",
    "    # Update training chart\n",
    "    mb.update_graph([[x, training_losses], [x, validation_losses], [x, validation_score]], [0,MAX_EPOCHS], [0,1])\n",
    "\n",
    "    # Save model\n",
    "    if best_score < new_score:\n",
    "        mb.write(f\"Improve F1 from {best_score} to {new_score}\")\n",
    "        best_score = new_score\n",
    "\n",
    "        # Saving model: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "        torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_data, model, device, threshold):\n",
    "    \"\"\" Predict image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path: str\n",
    "        image to predict\n",
    "    model: nn.Module\n",
    "        model used to predict\n",
    "    device: str\n",
    "        'cpu' or 'cuda'\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        list of label indices\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        ps = model(image_data.unsqueeze(0).to(device))\n",
    "        ps = ps[0]\n",
    "        for i in range(ps.size()[0]):\n",
    "            if ps[i].item() >= threshold:\n",
    "                return 1.\n",
    "            else:\n",
    "                return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet50(\n",
       "  (net): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 - 0.8653846153846154\n",
      "0.05 - 0.8669871794871795\n",
      "0.1 - 0.8637820512820513\n",
      "0.15 - 0.8637820512820513\n",
      "0.2 - 0.8685897435897436\n",
      "0.25 - 0.8685897435897436\n",
      "0.3 - 0.875\n",
      "0.35 - 0.875\n",
      "0.4 - 0.8733974358974359\n",
      "0.45 - 0.8717948717948718\n",
      "0.5 - 0.8717948717948718\n",
      "0.55 - 0.8766025641025641\n",
      "0.6 - 0.8766025641025641\n",
      "0.65 - 0.8782051282051282\n",
      "0.7 - 0.8782051282051282\n",
      "0.75 - 0.8782051282051282\n",
      "0.8 - 0.8782051282051282\n",
      "0.85 - 0.8782051282051282\n",
      "0.9 - 0.8766025641025641\n",
      "0.95 - 0.875\n",
      "1.0 - 0.8766025641025641\n",
      "1.05 - 0.8766025641025641\n",
      "1.1 - 0.8766025641025641\n",
      "1.15 - 0.8766025641025641\n",
      "1.2 - 0.8782051282051282\n",
      "1.25 - 0.8798076923076923\n",
      "1.3 - 0.8798076923076923\n",
      "1.35 - 0.8798076923076923\n",
      "1.4 - 0.8798076923076923\n",
      "1.45 - 0.8782051282051282\n",
      "1.5 - 0.8782051282051282\n",
      "1.55 - 0.8782051282051282\n",
      "1.6 - 0.8782051282051282\n",
      "1.65 - 0.8798076923076923\n",
      "1.7 - 0.8798076923076923\n",
      "1.75 - 0.8782051282051282\n",
      "1.8 - 0.8798076923076923\n",
      "1.85 - 0.8798076923076923\n",
      "1.9 - 0.8798076923076923\n",
      "1.95 - 0.8814102564102564\n",
      "2.0 - 0.8814102564102564\n",
      "2.05 - 0.8846153846153846\n",
      "2.1 - 0.8846153846153846\n",
      "2.15 - 0.8862179487179487\n",
      "2.2 - 0.8862179487179487\n",
      "2.25 - 0.8862179487179487\n",
      "2.3 - 0.8862179487179487\n",
      "2.35 - 0.8862179487179487\n",
      "2.4 - 0.8894230769230769\n",
      "2.45 - 0.8894230769230769\n",
      "2.5 - 0.8894230769230769\n",
      "2.55 - 0.8894230769230769\n",
      "2.6 - 0.8894230769230769\n",
      "2.65 - 0.8894230769230769\n",
      "2.7 - 0.8878205128205128\n",
      "2.75 - 0.8862179487179487\n",
      "2.8 - 0.8878205128205128\n",
      "2.85 - 0.8862179487179487\n",
      "2.9 - 0.8862179487179487\n",
      "2.95 - 0.8894230769230769\n",
      "3.0 - 0.8894230769230769\n",
      "3.05 - 0.8894230769230769\n",
      "3.1 - 0.8862179487179487\n",
      "3.15 - 0.8846153846153846\n",
      "3.2 - 0.8846153846153846\n",
      "3.25 - 0.8830128205128205\n",
      "3.3 - 0.8846153846153846\n",
      "3.35 - 0.8846153846153846\n",
      "3.4 - 0.8862179487179487\n",
      "3.45 - 0.8878205128205128\n",
      "3.5 - 0.8894230769230769\n",
      "3.55 - 0.8878205128205128\n",
      "3.6 - 0.8846153846153846\n",
      "3.65 - 0.8846153846153846\n",
      "3.7 - 0.8830128205128205\n",
      "3.75 - 0.8862179487179487\n",
      "3.8 - 0.8862179487179487\n",
      "3.85 - 0.8878205128205128\n",
      "3.9 - 0.8878205128205128\n",
      "3.95 - 0.8862179487179487\n",
      "4.0 - 0.8894230769230769\n",
      "4.05 - 0.8894230769230769\n",
      "4.1 - 0.8862179487179487\n",
      "4.15 - 0.8878205128205128\n",
      "4.2 - 0.8894230769230769\n",
      "4.25 - 0.8894230769230769\n",
      "4.3 - 0.8894230769230769\n",
      "4.35 - 0.8894230769230769\n",
      "4.4 - 0.8878205128205128\n",
      "4.45 - 0.8878205128205128\n",
      "4.5 - 0.8878205128205128\n",
      "4.55 - 0.8862179487179487\n",
      "4.6 - 0.8862179487179487\n",
      "4.65 - 0.8862179487179487\n",
      "4.7 - 0.8846153846153846\n",
      "4.75 - 0.8830128205128205\n",
      "4.8 - 0.8846153846153846\n",
      "4.85 - 0.8846153846153846\n",
      "4.9 - 0.8862179487179487\n",
      "4.95 - 0.8878205128205128\n",
      "5.0 - 0.8878205128205128\n",
      "5.05 - 0.8878205128205128\n",
      "5.1 - 0.8878205128205128\n",
      "5.15 - 0.8894230769230769\n",
      "5.2 - 0.8894230769230769\n",
      "5.25 - 0.8894230769230769\n",
      "5.3 - 0.8878205128205128\n",
      "5.35 - 0.8846153846153846\n",
      "5.4 - 0.8846153846153846\n",
      "5.45 - 0.8814102564102564\n",
      "5.5 - 0.8798076923076923\n",
      "5.55 - 0.8782051282051282\n",
      "5.6 - 0.8782051282051282\n",
      "5.65 - 0.8766025641025641\n",
      "5.7 - 0.8782051282051282\n",
      "5.75 - 0.8782051282051282\n",
      "5.8 - 0.8782051282051282\n",
      "5.85 - 0.8782051282051282\n",
      "5.9 - 0.8766025641025641\n",
      "5.95 - 0.8766025641025641\n",
      "6.0 - 0.875\n",
      "6.05 - 0.875\n",
      "6.1 - 0.875\n",
      "6.15 - 0.8733974358974359\n",
      "6.2 - 0.8717948717948718\n",
      "6.25 - 0.8717948717948718\n",
      "6.3 - 0.8685897435897436\n",
      "6.35 - 0.8685897435897436\n",
      "6.4 - 0.8669871794871795\n",
      "6.45 - 0.8669871794871795\n",
      "6.5 - 0.8637820512820513\n",
      "6.55 - 0.8605769230769231\n",
      "6.6 - 0.8605769230769231\n",
      "6.65 - 0.8573717948717948\n",
      "6.7 - 0.8573717948717948\n",
      "6.75 - 0.8541666666666666\n",
      "6.8 - 0.8461538461538461\n",
      "6.85 - 0.8461538461538461\n",
      "6.9 - 0.8461538461538461\n",
      "6.95 - 0.8461538461538461\n",
      "7.0 - 0.8461538461538461\n",
      "7.05 - 0.844551282051282\n",
      "7.1 - 0.844551282051282\n",
      "7.15 - 0.844551282051282\n",
      "7.2 - 0.8381410256410257\n",
      "7.25 - 0.8381410256410257\n",
      "7.3 - 0.8349358974358975\n",
      "7.35 - 0.8349358974358975\n",
      "7.4 - 0.8333333333333334\n",
      "7.45 - 0.8333333333333334\n",
      "7.5 - 0.8301282051282052\n",
      "7.55 - 0.8301282051282052\n",
      "7.6 - 0.8285256410256411\n",
      "7.65 - 0.8285256410256411\n",
      "7.7 - 0.8253205128205128\n",
      "7.75 - 0.8253205128205128\n",
      "7.8 - 0.8237179487179487\n",
      "7.85 - 0.8221153846153846\n",
      "7.9 - 0.8205128205128205\n",
      "7.95 - 0.8189102564102564\n",
      "8.0 - 0.8157051282051282\n",
      "8.05 - 0.8125\n",
      "8.1 - 0.8092948717948718\n",
      "8.15 - 0.8060897435897436\n",
      "8.2 - 0.8044871794871795\n",
      "8.25 - 0.8044871794871795\n",
      "8.3 - 0.8060897435897436\n",
      "8.35 - 0.8060897435897436\n",
      "8.4 - 0.8044871794871795\n",
      "8.45 - 0.7980769230769231\n",
      "8.5 - 0.7964743589743589\n",
      "8.55 - 0.7948717948717948\n",
      "8.6 - 0.7948717948717948\n",
      "8.65 - 0.7916666666666666\n",
      "8.7 - 0.7900641025641025\n",
      "8.75 - 0.7868589743589743\n",
      "8.8 - 0.7852564102564102\n",
      "8.85 - 0.782051282051282\n",
      "8.9 - 0.7836538461538461\n",
      "8.95 - 0.780448717948718\n",
      "9.0 - 0.7772435897435898\n",
      "9.05 - 0.7772435897435898\n",
      "9.1 - 0.7756410256410257\n",
      "9.15 - 0.7740384615384616\n",
      "9.2 - 0.7740384615384616\n",
      "9.25 - 0.7692307692307693\n",
      "9.3 - 0.7708333333333334\n",
      "9.35 - 0.7644230769230769\n",
      "9.4 - 0.7628205128205128\n",
      "9.45 - 0.7596153846153846\n",
      "9.5 - 0.7564102564102564\n",
      "9.55 - 0.7548076923076923\n",
      "9.6 - 0.7532051282051282\n",
      "9.65 - 0.75\n",
      "9.7 - 0.7467948717948718\n",
      "9.75 - 0.7467948717948718\n",
      "9.8 - 0.7451923076923077\n",
      "9.85 - 0.7419871794871795\n",
      "9.9 - 0.7403846153846154\n",
      "9.95 - 0.7387820512820513\n",
      "BestScore =  0.8894230769230769\n",
      "threshold =  2.4\n"
     ]
    }
   ],
   "source": [
    "maxScore = 0.\n",
    "thresholdPerfect = 0.\n",
    "for i in range(0, 200):\n",
    "    element = i*5/100\n",
    "    count_truth = 0\n",
    "    count_img = 0\n",
    "    for img, label in test_dataset:\n",
    "        if predict(img, model, device, element) == label[0]:\n",
    "            count_truth+=1\n",
    "        count_img+=1\n",
    "    if (count_truth/count_img) > maxScore:\n",
    "        maxScore = count_truth/count_img\n",
    "        thresholdPerfect = element\n",
    "    print(f'{element} - {count_truth/count_img}')\n",
    "\n",
    "\n",
    "print(\"BestScore = \",maxScore)\n",
    "print(\"threshold = \", thresholdPerfect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
