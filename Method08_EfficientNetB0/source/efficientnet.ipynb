{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-22 17:09:03--  https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/img.jpg\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 116068 (113K) [image/jpeg]\r\n",
      "Saving to: ‘img.jpg’\r\n",
      "\r\n",
      "img.jpg             100%[===================>] 113.35K  --.-KB/s    in 0.04s   \r\n",
      "\r\n",
      "2019-07-22 17:09:05 (3.02 MB/s) - ‘img.jpg’ saved [116068/116068]\r\n",
      "\r\n",
      "--2019-07-22 17:09:05--  https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/labels_map.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 31565 (31K) [text/plain]\r\n",
      "Saving to: ‘labels_map.txt’\r\n",
      "\r\n",
      "labels_map.txt       40%[=======>            ]  12.63K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2019-07-22 17:09:06 (91.4 MB/s) - Read error at byte 12936/31565 (Error in the pull function.). Retrying.\r\n",
      "\r\n",
      "--2019-07-22 17:09:07--  (try: 2)  https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/labels_map.txt\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 206 Partial Content\r\n",
      "Length: 31565 (31K), 18629 (18K) remaining [text/plain]\r\n",
      "Saving to: ‘labels_map.txt’\r\n",
      "\r\n",
      "labels_map.txt      100%[++++++++===========>]  30.83K  --.-KB/s    in 0.01s   \r\n",
      "\r\n",
      "2019-07-22 17:09:07 (1.40 MB/s) - ‘labels_map.txt’ saved [31565/31565]\r\n",
      "\r\n",
      "Collecting efficientnet_pytorch\r\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/e9/81aa23322344835403b8852e7c24938edf7945da729b653d4cfa779e7571/efficientnet_pytorch-0.3.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from efficientnet_pytorch) (1.1.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torch->efficientnet_pytorch) (1.16.4)\r\n",
      "Installing collected packages: efficientnet-pytorch\r\n",
      "Successfully installed efficientnet-pytorch-0.3.0\r\n"
     ]
    }
   ],
   "source": [
    "# Download image and class labels\n",
    "!wget https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/img.jpg\n",
    "!wget https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/labels_map.txt\n",
    "# Get EfficientNet PyTorch\n",
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224                              # Image size (224x224)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]         # Mean of ImageNet dataset (used for normalization)\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]          # Std of ImageNet dataset (used for normalization)\n",
    "BATCH_SIZE = 60                           \n",
    "LEARNING_RATE = 0.005\n",
    "LEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\n",
    "LEARNING_RATE_SCHEDULE_PATIENCE = 5           # Parameter used for reducing learning rate\n",
    "MAX_EPOCHS = 135\n",
    "\n",
    "USE_BCELOGIT = True\n",
    "USE_WEIGHT = True\n",
    "# LOSS WEIGHT\n",
    "pos_w = None\n",
    "w = None\n",
    "if USE_WEIGHT:\n",
    "    pos_w=[1.04]\n",
    "    w = [1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Define path to the data directory\n",
    "data_dir = Path('../input/chest_xray/chest_xray')\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = data_dir / 'train'\n",
    "\n",
    "# Path to validation directory\n",
    "val_dir = data_dir / 'val'\n",
    "\n",
    "# Path to test directory\n",
    "test_dir = data_dir / 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load img**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/chest_xray/chest_xray/train/PNEUMONIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/chest_xray/chest_xray/train/NORMAL/NO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/chest_xray/chest_xray/train/PNEUMONIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/chest_xray/chest_xray/train/PNEUMONIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/chest_xray/chest_xray/train/NORMAL/IM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label\n",
       "0  ../input/chest_xray/chest_xray/train/PNEUMONIA...      1\n",
       "1  ../input/chest_xray/chest_xray/train/NORMAL/NO...      0\n",
       "2  ../input/chest_xray/chest_xray/train/PNEUMONIA...      1\n",
       "3  ../input/chest_xray/chest_xray/train/PNEUMONIA...      1\n",
       "4  ../input/chest_xray/chest_xray/train/NORMAL/IM...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = train_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "train_data = []\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in normal_cases:\n",
    "    train_data.append((img,0))\n",
    "    train_data.append((img,0))\n",
    "    train_data.append((img,0))\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in pneumonia_cases:\n",
    "    train_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list \n",
    "train_data = pd.DataFrame(train_data, columns=['path', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data \n",
    "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/chest_xray/chest_xray/val/NORMAL/NORM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/chest_xray/chest_xray/val/PNEUMONIA/p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/chest_xray/chest_xray/val/NORMAL/NORM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/chest_xray/chest_xray/val/NORMAL/NORM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/chest_xray/chest_xray/val/PNEUMONIA/p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label\n",
       "0  ../input/chest_xray/chest_xray/val/NORMAL/NORM...      0\n",
       "1  ../input/chest_xray/chest_xray/val/PNEUMONIA/p...      1\n",
       "2  ../input/chest_xray/chest_xray/val/NORMAL/NORM...      0\n",
       "3  ../input/chest_xray/chest_xray/val/NORMAL/NORM...      0\n",
       "4  ../input/chest_xray/chest_xray/val/PNEUMONIA/p...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = val_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "valid_data = []\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in normal_cases:\n",
    "    valid_data.append((img, 0))\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in pneumonia_cases:\n",
    "    valid_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list \n",
    "valid_data = pd.DataFrame(valid_data, columns=['path', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data \n",
    "valid_data = valid_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/chest_xray/chest_xray/test/PNEUMONIA/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/chest_xray/chest_xray/test/NORMAL/NOR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/chest_xray/chest_xray/test/PNEUMONIA/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/chest_xray/chest_xray/test/NORMAL/NOR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/chest_xray/chest_xray/test/PNEUMONIA/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  label\n",
       "0  ../input/chest_xray/chest_xray/test/PNEUMONIA/...      1\n",
       "1  ../input/chest_xray/chest_xray/test/NORMAL/NOR...      0\n",
       "2  ../input/chest_xray/chest_xray/test/PNEUMONIA/...      1\n",
       "3  ../input/chest_xray/chest_xray/test/NORMAL/NOR...      0\n",
       "4  ../input/chest_xray/chest_xray/test/PNEUMONIA/...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "test_data = []\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in normal_cases:\n",
    "    test_data.append((img, 0))\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in pneumonia_cases:\n",
    "    test_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list \n",
    "test_data = pd.DataFrame(test_data, columns=['path', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data \n",
    "test_data = test_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Show Figue of Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4023\n",
      "1    3875\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = train_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results \n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "plt.title('Number of cases', fontsize=14)\n",
    "plt.xlabel('Case type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is very imbalance, so we need Aug, Overstampling or Understampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    8\n",
      "0    8\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = valid_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results \n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "plt.title('Number of cases', fontsize=14)\n",
    "plt.xlabel('Case type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    390\n",
      "0    234\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = test_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results \n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "plt.title('Number of cases', fontsize=14)\n",
    "plt.xlabel('Case type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create FudusDataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imgaug in /opt/conda/lib/python3.6/site-packages (0.2.6)\r\n",
      "Requirement already satisfied: numpy>=1.7.0 in /opt/conda/lib/python3.6/site-packages (from imgaug) (1.16.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from imgaug) (1.12.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from imgaug) (1.2.1)\r\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in /opt/conda/lib/python3.6/site-packages (from imgaug) (0.15.0)\r\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug) (1.0.3)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug) (2.2)\r\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug) (6.0.0)\r\n",
      "Requirement already satisfied: imageio>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug) (2.5.0)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image>=0.11.0->imgaug) (3.0.3)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug) (4.4.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug) (2.4.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug) (2.8.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug) (41.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa \n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "\n",
    "class FundusDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, image_size, normalization):\n",
    "        \"\"\"\n",
    "        Init Dataset\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dataframe: pandas.DataFrame\n",
    "            dataframe contains all information of images\n",
    "        image_size: int\n",
    "            image size to rescale\n",
    "        normalization: bool\n",
    "            whether applying normalization with mean and std from ImageNet or not\n",
    "        \"\"\"\n",
    "        self.image_paths = [] # List of image paths\n",
    "        self.image_labels = [] # List of image labels\n",
    "        self.prev_path = None\n",
    "        self.prev_prev_path = None\n",
    "        \n",
    "        # Define list of image transformations\n",
    "        image_transformation = [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor()\n",
    "        ]\n",
    "        \n",
    "        if normalization:\n",
    "            # Normalization with mean and std from ImageNet\n",
    "            image_transformation.append(transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD))\n",
    "        \n",
    "        self.image_transformation = transforms.Compose(image_transformation)\n",
    "        \n",
    "        # Get all image paths and image labels from dataframe\n",
    "        for index, row in dataframe.iterrows():\n",
    "            self.image_paths.append(row.path)\n",
    "            self.image_labels.append(row.label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Read image at index and convert to torch Tensor\n",
    "        \"\"\"\n",
    "        # Read image\n",
    "        image_path = self.image_paths[index]\n",
    "        image_data = Image.open(image_path).convert(\"RGB\") # Convert image to RGB channels\n",
    "        \n",
    "        # TODO: Image augmentation code would be placed here\n",
    "        \n",
    "        # Resize and convert image to torch tensor \n",
    "        image_data = self.image_transformation(image_data)\n",
    "        \n",
    "        return image_data, torch.tensor([self.image_labels[index]*1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FundusDataset(train_data, IMAGE_SIZE, True)\n",
    "valid_dataset = FundusDataset(valid_data, IMAGE_SIZE, True)\n",
    "test_dataset = FundusDataset(test_data, IMAGE_SIZE, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for img, label in test_dataset:\n",
    "    print(img.size())\n",
    "    if label == 0:\n",
    "        print(0)\n",
    "    else:\n",
    "        print(1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224])\n",
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "for data, label in valid_dataloader:\n",
    "    print(data.size())\n",
    "    print(label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Efficient net\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model_name = 'efficientnet-b2'\n",
    "\n",
    "class EffNet(nn.Module):\n",
    "    def __init__(self, num_classes, is_trained=True):\n",
    "        \"\"\"\n",
    "        Init model architecture\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        num_classes: int\n",
    "            number of classes\n",
    "        is_trained: bool\n",
    "            whether using pretrained model from ImageNet or not\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load the pretrained \n",
    "        self.net = EfficientNet.from_pretrained(model_name)\n",
    "\n",
    "        \n",
    "        # Get the input dimension of last layer\n",
    "        kernel_count = self.net._fc.in_features\n",
    "        \n",
    "        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n",
    "        if not USE_BCELOGIT:\n",
    "            self.net._fc = nn.Sequential(nn.Linear(kernel_count, num_classes)\n",
    "                                       ,nn.Sigmoid()\n",
    "                                       )\n",
    "        else:\n",
    "            self.net._fc = nn.Sequential(nn.Linear(kernel_count, num_classes)\n",
    "                                       #,nn.Sigmoid()\n",
    "                                       )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward the netword with the inputs\n",
    "        \"\"\"\n",
    "        output = self.net(inputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** Create Model & count params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://storage.googleapis.com/public-models/efficientnet-b2-27687264.pth\" to /tmp/.cache/torch/checkpoints/efficientnet-b2-27687264.pth\n",
      "100%|██████████| 36797453/36797453 [00:00<00:00, 74836633.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EffNet(\n",
       "  (net): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          16, 16, kernel_size=(3, 3), stride=(1, 1), groups=16, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          16, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(5, 5), stride=[1, 1], groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=[2, 2], groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(3, 3), stride=[1, 1], groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(352, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2112, 2112, kernel_size=(3, 3), stride=(1, 1), groups=2112, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2112, 88, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          88, 2112, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(352, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1408, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_fc): Sequential(\n",
       "      (0): Linear(in_features=1408, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EffNet(num_classes=1).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7702403"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function, optimizer, and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "if pos_w is not None:\n",
    "    pos_w = torch.tensor(pos_w, device=device)\n",
    "if w is not None:\n",
    "    w = torch.tensor(w, device=device)\n",
    "\n",
    "if USE_BCELOGIT:\n",
    "    loss_criteria = nn.BCEWithLogitsLoss(weight=w, pos_weight=pos_w)\n",
    "else:\n",
    "    loss_criteria = nn.BCELoss(weight=w)\n",
    "if device == 'cuda':\n",
    "    loss_criteria.cuda()\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate will be reduced automatically during training\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = LEARNING_RATE_SCHEDULE_FACTOR, patience = LEARNING_RATE_SCHEDULE_PATIENCE, mode = 'max', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_f1(y_gt, y_pred):\n",
    "    \"\"\" Calculate F1 for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        F1 of each class\n",
    "    \"\"\"\n",
    "    f1_out = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = (y_pred.to(\"cpu\").numpy() > 0.5) * 1.0\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        f1_out.append(f1_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return f1_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training each epoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb):\n",
    "    \"\"\"\n",
    "    Epoch training\n",
    "\n",
    "    Paramteters\n",
    "    -----------\n",
    "    epoch: int\n",
    "      epoch number\n",
    "    model: torch Module\n",
    "      model to train\n",
    "    train_dataloader: Dataset\n",
    "      data loader for training\n",
    "    device: str\n",
    "      \"cpu\" or \"cuda\"\n",
    "    loss_criteria: loss function\n",
    "      loss function used for training\n",
    "    optimizer: torch optimizer\n",
    "      optimizer used for training\n",
    "    mb: master bar of fastprogress\n",
    "      progress to log\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "      training loss\n",
    "    \"\"\"\n",
    "    # Switch model to training mode\n",
    "    model.train()\n",
    "    training_loss = 0 # Storing sum of training losses\n",
    "   \n",
    "    # For each batch\n",
    "    for batch, (images, labels) in enumerate(progress_bar(train_dataloader, parent=mb)):\n",
    "        \n",
    "        # Move X, Y  to device (GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear previous gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Feed forward the model\n",
    "        pred = model(images)\n",
    "        loss = loss_criteria(pred, labels)\n",
    "\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training loss after each batch\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        mb.child.comment = f'Training loss {training_loss/(batch+1)}'\n",
    "\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    # return training loss\n",
    "    return training_loss/len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(epoch, model, val_loader, device, loss_criteria, mb):\n",
    "    \"\"\"\n",
    "    Validate model on validation dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch: int\n",
    "        epoch number\n",
    "    model: torch Module\n",
    "        model used for validation\n",
    "    val_loader: Dataset\n",
    "        data loader of validation set\n",
    "    device: str\n",
    "        \"cuda\" or \"cpu\"\n",
    "    loss_criteria: loss function\n",
    "      loss function used for training\n",
    "    mb: master bar of fastprogress\n",
    "      progress to log\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        loss on validation set\n",
    "    float\n",
    "        metric score on validation set\n",
    "    \"\"\"\n",
    "\n",
    "    # Switch model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0                                   # Total loss of model on validation set\n",
    "    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n",
    "    out_gt = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n",
    "\n",
    "    with torch.no_grad(): # Turn off gradient\n",
    "        # For each batch\n",
    "        for step, (images, labels) in enumerate(progress_bar(val_loader, parent=mb)):\n",
    "            # Move images, labels to device (GPU)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Update groundtruth values\n",
    "            out_gt = torch.cat((out_gt,  labels), 0)\n",
    "\n",
    "            # Feed forward the model\n",
    "            ps = model(images)\n",
    "            loss = loss_criteria(ps, labels)\n",
    "\n",
    "            # Update prediction values\n",
    "            out_pred = torch.cat((out_pred, ps), 0)\n",
    "\n",
    "            # Update validation loss after each batch\n",
    "            val_loss += loss\n",
    "            mb.child.comment = f'Validation loss {val_loss/(step+1)}'\n",
    "\n",
    "    # Clear memory\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    # return validation loss, and metric score\n",
    "    return val_loss/len(val_loader), np.array(multi_label_f1(out_gt, out_pred)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='17' class='' max='135', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.59% [17/135 45:43<5:17:23 Best F1 score: 1.0]\n",
       "    </div>\n",
       "    \n",
       "Finish training epoch 0 with loss 0.1179<p>Finish validation epoch 0 with loss 1.8213 and score 0.6957<p>Improve F1 from 0 to 0.6956521739130436<p>Finish training epoch 1 with loss 0.0583<p>Finish validation epoch 1 with loss 0.5707 and score 0.8889<p>Improve F1 from 0.6956521739130436 to 0.888888888888889<p>Finish training epoch 2 with loss 0.0348<p>Finish validation epoch 2 with loss 0.1814 and score 0.9412<p>Improve F1 from 0.888888888888889 to 0.9411764705882353<p>Finish training epoch 3 with loss 0.0207<p>Finish validation epoch 3 with loss 0.3193 and score 0.9412<p>Finish training epoch 4 with loss 0.0217<p>Finish validation epoch 4 with loss 0.1975 and score 1.0000<p>Improve F1 from 0.9411764705882353 to 1.0<p>Finish training epoch 5 with loss 0.0265<p>Finish validation epoch 5 with loss 1.2097 and score 0.2222<p>Finish training epoch 6 with loss 0.0347<p>Finish validation epoch 6 with loss 1.2847 and score 0.7619<p>Finish training epoch 7 with loss 0.0145<p>Finish validation epoch 7 with loss 0.4714 and score 0.8889<p>Finish training epoch 8 with loss 0.0138<p>Finish validation epoch 8 with loss 0.0322 and score 1.0000<p>Finish training epoch 9 with loss 0.0210<p>Finish validation epoch 9 with loss 0.0906 and score 1.0000<p>Finish training epoch 10 with loss 0.0116<p>Finish validation epoch 10 with loss 0.9220 and score 0.7619<p>Finish training epoch 11 with loss 0.0069<p>Finish validation epoch 11 with loss 0.0057 and score 1.0000<p>Finish training epoch 12 with loss 0.0010<p>Finish validation epoch 12 with loss 0.0012 and score 1.0000<p>Finish training epoch 13 with loss 0.0006<p>Finish validation epoch 13 with loss 0.0007 and score 1.0000<p>Finish training epoch 14 with loss 0.0010<p>Finish validation epoch 14 with loss 0.0019 and score 1.0000<p>Finish training epoch 15 with loss 0.0005<p>Finish validation epoch 15 with loss 0.0015 and score 1.0000<p>Finish training epoch 16 with loss 0.0004<p>Finish validation epoch 16 with loss 0.0007 and score 1.0000<p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='29' class='' max='132', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      21.97% [29/132 00:38<02:15 Training loss 0.0002815132675174215]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    10: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch    16: reducing learning rate of group 0 to 5.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "# Best F1 value during training\n",
    "best_score = 0\n",
    "model_path = \"efficientB4.pth\"\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "validation_score = []\n",
    "\n",
    "\n",
    "# Config progress bar\n",
    "mb = master_bar(range(MAX_EPOCHS))\n",
    "mb.names = ['Training loss', 'Validation loss', 'Validation F1']\n",
    "x = []\n",
    "\n",
    "# Training each epoch\n",
    "for epoch in mb:\n",
    "    mb.first_bar.comment = f'Best F1 score: {best_score}'\n",
    "    x.append(epoch)\n",
    "\n",
    "    # Training\n",
    "    train_loss = epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb)\n",
    "    mb.write('Finish training epoch {} with loss {:.4f}'.format(epoch, train_loss))\n",
    "    training_losses.append(train_loss)\n",
    "\n",
    "    # Evaluating\n",
    "    val_loss, new_score = evaluating(epoch, model, valid_dataloader, device, loss_criteria, mb)\n",
    "    mb.write('Finish validation epoch {} with loss {:.4f} and score {:.4f}'.format(epoch, val_loss, new_score))\n",
    "    validation_losses.append(val_loss)\n",
    "    validation_score.append(new_score)\n",
    "\n",
    "    # Update learning rate\n",
    "    lr_scheduler.step(new_score)\n",
    "\n",
    "    # Update training chart\n",
    "    mb.update_graph([[x, training_losses], [x, validation_losses], [x, validation_score]], [0,MAX_EPOCHS], [0,1])\n",
    "\n",
    "    # Save model\n",
    "    if best_score < new_score:\n",
    "        mb.write(f\"Improve F1 from {best_score} to {new_score}\")\n",
    "        best_score = new_score\n",
    "\n",
    "        # Saving model: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "        torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_data, model, device, threshold):\n",
    "    \"\"\" Predict image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_path: str\n",
    "        image to predict\n",
    "    model: nn.Module\n",
    "        model used to predict\n",
    "    device: str\n",
    "        'cpu' or 'cuda'\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        list of label indices\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        ps = model(image_data.unsqueeze(0).to(device))\n",
    "        ps = ps[0]\n",
    "        if ps[0].item() >= threshold: \n",
    "            return 1.\n",
    "    return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EffNet(\n",
       "  (net): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          16, 16, kernel_size=(3, 3), stride=(1, 1), groups=16, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          16, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(3, 3), stride=(1, 1), groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(88, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          528, 528, kernel_size=(5, 5), stride=[1, 1], groups=528, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(528, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          528, 22, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          22, 528, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=(1, 1), groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(120, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          720, 720, kernel_size=(5, 5), stride=[2, 2], groups=720, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(720, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          720, 30, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          30, 720, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(5, 5), stride=(1, 1), groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(208, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1248, 1248, kernel_size=(3, 3), stride=[1, 1], groups=1248, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1248, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1248, 52, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          52, 1248, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(352, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2112, 2112, kernel_size=(3, 3), stride=(1, 1), groups=2112, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2112, 88, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          88, 2112, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(352, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1408, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_fc): Sequential(\n",
       "      (0): Linear(in_features=1408, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  __output__.json  efficientB4.pth  img.jpg  labels_map.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 - 0.7548076923076923\n",
      "0.05 - 0.7564102564102564\n",
      "0.1 - 0.7612179487179487\n",
      "0.15 - 0.7628205128205128\n",
      "0.2 - 0.7644230769230769\n",
      "0.25 - 0.7660256410256411\n",
      "0.3 - 0.7724358974358975\n",
      "0.35 - 0.7756410256410257\n",
      "0.4 - 0.7788461538461539\n",
      "0.45 - 0.7852564102564102\n",
      "0.5 - 0.7868589743589743\n",
      "0.55 - 0.7916666666666666\n",
      "0.6 - 0.7948717948717948\n",
      "0.65 - 0.7964743589743589\n",
      "0.7 - 0.7964743589743589\n",
      "0.75 - 0.8012820512820513\n",
      "0.8 - 0.8044871794871795\n",
      "0.85 - 0.8044871794871795\n",
      "0.9 - 0.8108974358974359\n",
      "0.95 - 0.8141025641025641\n",
      "1.0 - 0.8141025641025641\n",
      "1.05 - 0.8173076923076923\n",
      "1.1 - 0.8237179487179487\n",
      "1.15 - 0.8269230769230769\n",
      "1.2 - 0.8269230769230769\n",
      "1.25 - 0.8269230769230769\n",
      "1.3 - 0.8317307692307693\n",
      "1.35 - 0.8365384615384616\n",
      "1.4 - 0.8349358974358975\n",
      "1.45 - 0.842948717948718\n",
      "1.5 - 0.8477564102564102\n",
      "1.55 - 0.8493589743589743\n",
      "1.6 - 0.8525641025641025\n",
      "1.65 - 0.8525641025641025\n",
      "1.7 - 0.8525641025641025\n",
      "1.75 - 0.8541666666666666\n",
      "1.8 - 0.8557692307692307\n",
      "1.85 - 0.8573717948717948\n",
      "1.9 - 0.8573717948717948\n",
      "1.95 - 0.8637820512820513\n",
      "2.0 - 0.8653846153846154\n",
      "BestScore =  0.8653846153846154\n",
      "threshold =  2.0\n"
     ]
    }
   ],
   "source": [
    "maxScore = 0.\n",
    "thresholdPerfect = 0.\n",
    "for i in range(0, 41):\n",
    "    element = i*5/100\n",
    "    count_truth = 0\n",
    "    count_img = 0\n",
    "    for img, label in test_dataset:\n",
    "        if predict(img, model, device, element) == label[0]:\n",
    "            count_truth+=1\n",
    "        count_img+=1\n",
    "    if (count_truth/count_img) > maxScore:\n",
    "        maxScore = count_truth/count_img\n",
    "        thresholdPerfect = element\n",
    "    print(f'{element} - {count_truth/count_img}')\n",
    "\n",
    "\n",
    "print(\"BestScore = \",maxScore)\n",
    "print(\"threshold = \", thresholdPerfect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
